\chapter{Deep}
\section{Code online}

To promote reproducibility, we share all our code online. We follow the NeurIPS instructions which allow sharing only anonymized repositories. We provide one respository with the code\footnote{\texttt{https://anonymous.4open.science/r/AccuracyAtTop-7562}} and one repository with numerical experiments.\footnote{\texttt{https://anonymous.4open.science/r/AccuracyAtTop\_DeepTopPush-834E}}

\section{Theorem \ref{theorem:convergence} for Rec@K}

The assumption of Theorem \ref{theorem:convergence} requires that the threshold is computing from negative samples and the objective for positive samples. This does not hold for Rec@K. We will show that we can obtain a similar result even for this case.

The proof of Theorem \ref{theorem:convergence} is based on Lemma \ref{lemma:convergence}. We will now obtain the variant of Lemma \ref{lemma:convergence} for Rec@K. First, we realize that if the threshold index $j^*$ corresponds to a negative sample, the computation will not change and therefore
\begin{equation*}
  \EE\Brac{\nabla \hat L(\bm w) \mid \hat j=j^*\text{ is an index of a negative sample}}
  =  \nabla L(\bm w).
\end{equation*}
On the other hand, when $j^*$ corresponds to a positive sample, it needs to be always present in the minibatch selection and there are effectively only $\nmin^+-1$ positive samples in the minibatch. Then
\begin{equation*}
  \EE\Brac{\nabla \hat L(\bm w) \mid \hat j=j^*\text{ is an index of a positive sample}}
  = \frac{\nmin^+-1}{\nmin^+}\nabla L(\bm w).
\end{equation*}
Denote now $p$ the probability that the threshold corresponds to a positive sample. Then we have
\begin{equation*}
  \begin{aligned}
    \EE\Brac{\nabla \hat L(\bm w) \mid \hat j=j^*}
    & = (1-p)\nabla L(\bm w) + p\frac{\nmin^+-1}{\nmin^+}\nabla L(\bm w) \\
    & = \nabla L(\bm w) - \frac{p}{\nmin^+}\nabla L(\bm w).
\end{aligned}
\end{equation*}

Theorem \ref{theorem:convergence} will then be modified into
\begin{equation*}
  \begin{aligned}
    \bias(\bm w)
    & = \PP(\hat j\neq j^*) \Brac{\nabla L(\bm w) - \EE\Brac{\nabla \hat L(\bm w) \mid \hat j\neq j^*}} \\
    & \qquad - \PP(\hat j= j^*)\frac{p}{\nmin^+}\nabla L(\bm w).
  \end{aligned}
\end{equation*}
We changed the result by adding the last term. Usually the training set contains much less positive than negative samples. This implies that $p$ is assumed to be small and the extra term is small as well. Thefore, this change should have a negligible impact on the theorem implications.

\subsection{Used network architecture}\label{app:network}

For 3A4, we preprocessed the input with $9491$ into a $100$-dimensional input by PCA. Then we used two dense layers of size $100\times 50$ and $50\times 25$ with batch-normalization after these layers. The last layer was dense.

For FashionMNIST, we used a network alternating two hidden convolutional layers with two max-pooling layers finished with a dense layer. The convolutional layers used kernels $5\times 5$ and had $20$ and $50$ channels, respectively. For CIFAR100 and SVHN2, we increased the number of hidden and max-pooling layers from two to three. The convolutional layers used kernels $3\times 3$ and had $64$, $128$, and $128$ channels, respectively. A more detailed description can be found in our codes online. We are fully aware that these architectures are suboptimal. Since the accuracy at the top needs to select only a few relevant samples and the rest of the dataset's performance is irrelevant, such a network can be used. Moreover, using a simpler network has the advantage of faster experiments.

For ImageNet, we merged all turtles into the positive class and all non-turtles into the negative class. Then we used the pre-trained EfficientNet B0, where we replaced the last dense layer with $1000$ outputs by a dense layer into a scalar output.

\section{Dataset summary}

Table \ref{tab:DatasetsDeep} summarizes the used datasets. The Malware Detection dataset was represented by JSONs, which contain varying number of features. Moreover, many features are not scalar but have some hierarchical structure as well.

\begin{table}[!ht]
  \centering
  \begin{tabular}{@{}lcrrrrl@{}}
    \toprule
    && \multicolumn{2}{c}{Train}
    &  \multicolumn{2}{c}{Test}
    &  License\\
    \cmidrule(lr){3-4} \cmidrule(lr){5-6}
    \thead{Dataset}
      & \thead{$d$}
      & \thead{$n$}
      & \thead{$\frac{n^+}{n}$}
      & \thead{$n$}
      & \thead{$\frac{n^+}{n}$} 
      & \\
    \midrule
    FashionMNIST
      & $28 \times 28 \times 1$
      & 60 000 & 10.00\% & 10 000 & 10.00\%  & MIT \\
    CIFAR100
      & $32 \times 32 \times 3$
      & 50 000 & 1.00\% & 10 000 & 1.00\% & not specified \\
    SVHN2 extra
      & $32 \times 32 \times 3$
      & 604 388 & 17.28\% & 26 032 & 19.59\% & not specified \\
    ImageNet
      & $62 720 \times 1$
      & 1 281 167 & 0.51\% & 50000 & 0.50\% & registration \\
    3A4
      & $9491 \times 1$
      & 37 241 & 0.98\% & 37 241 & 1.07\% & CC BY 4.0 \\
    Malware Detection
      & variable
      & 6 580 166 & 87.22\% & 800 346 & 91.80\%  & proprietary\\
    \bottomrule
  \end{tabular}
  \caption{Summary of the used datasets with the number of features~$d$, number of samples~$n$ and the fraction of positive samples~$\frac{n^+}{n}$ in the training set.}
  \label{tab:DatasetsDeep}
\end{table}