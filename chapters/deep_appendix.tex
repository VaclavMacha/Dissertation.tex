\chapter{Appendix for Chapter~\ref{chap: deep}}

\lemmacovergencedeep*
\begin{proof}[Proof of Lemma~\ref{lemma:convergence} on page~\pageref{lemma:convergence}]
  If~$\indmax$ is unique, then the true threshold~$t$ is a differentiable function of weights~$\bm{w}$. The differentiability of~$L$ and~$\hat{L}$ follows from the chain rule. If~$\indmaxmb = \indmax$ holds, then the sampled gradient equals to
  \begin{equation}\label{eq:grad_min_aux}
    \nabla \hat L(\bm{w})
      = \frac{1}{\nmbpos} \sum_{i\in \Imbpos} l'(t - s_i) \Brac{\nabla f(\bm{x}_{\indmax}; \bm{w}) - \nabla f(\bm{x}_i; \bm{w})}.
  \end{equation}
  The summands are identical to the ones in~\eqref{eq: deep L gradient true}. Since the sum is performed with respect to positive samples, the threshold is computed from negative samples, the lemma statement follows.
\end{proof}

\thmcovergencedeep*
\begin{proof}[Proof of Theorem~\ref{theorem:convergence} on page~\pageref{theorem:convergence}]
  The law of total expectation implies
  \begin{equation*}
    \EE \nabla \hat L(\bm{w})
      = \PP \Brac[s]{\indmaxmb = \indmax} \EE \Brac[s]{\nabla \hat L(\bm{w}) \middle\vert \indmaxmb =\indmax}
      + \PP \Brac[s]{\indmaxmb \neq \indmax} \EE \Brac[s]{\nabla \hat L(\bm{w}) \middle\vert\indmaxmb\neq \indmax},
  \end{equation*}
  from where the statement follows due to~\eqref{eq:defin_bias} and Lemma~\ref{lemma:convergence}.
\end{proof}
