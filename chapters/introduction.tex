\chapter*{Introduction}
\addcontentsline{toc}{chapter}{Introduction}

The modern world is a world of information. In the past few decades, we have witnessed the rapid spread of computers, the internet, smart devices, sensors, etc., to every possible aspect of our lives. All these new technologies provide us with valuable data. But the amount of data is enormous, and the time when it was possible to process all the data manually is long gone. Thus, the need for methods that can process data automatically without explicitly being programmed for specific tasks has grown significantly. The field devoted to such methods is machine learning and covers many different approaches to achieving such goals~\cite{mitchell1997machine}. In this work, we focus on one specific subcategory of machine learning called classification~\cite{aggarwal2021artificial}.

Classification can be easily described on autonomous cars. Autonomous cars are getting more and more popular these days. One problem that they must solve is the recognition of road signs. Let's say that we have a lot of images of road signs. All these signs can be grouped into a finite number of classes based on their meaning. Classification aims to find a function that returns the corresponding class to which the road sign from the image belongs~\cite{swaminathan2019autonomous}. Such a function is usually called a classifier, and the process of finding a classifier is called training.

In most cases, the classifier is a parameterized function. In such a case, training is the process of finding parameter values for which the classification is most accurate. To be able to train the best parameter values, we need a so-called training set. In the case of classification, each data point in the training set consists of features and a corresponding label. The features describe the object of interest in a way understandable for computers. The label is the identifier of the class to which the object of interest belongs. Problems that assume a labeled training set are called supervised learning problems~\cite{aggarwal2021artificial}. In our example, the features are individual pixels of the image of the road sign, and the label is its type. The labels in the training set are essential because they allow us to determine which classifier parameters provide the most accurate predictions. However, they are usually challenging and expensive to obtain, as the labeling process must be done manually by a person with experience in the corresponding field. Notably, the labels are only used during training. Once the training is finished, only the features are needed to use the classifier.

The problem of classification is very important, and many real-world problems can be formulated as classification problems:
\begin{itemize}
  \item \textbf{Autonomous Cars:} As we have already mentioned, the classification can be used for autonomous cars, for example for road sign recognition~\cite{swaminathan2019autonomous}.
  \item \textbf{Medical Diagnosis:} In medicine, classification is often used to improve disease diagnosis. In such a case, the features are medical records such as the patient's blood tests, temperature, or x-ray images. The classes are whether the patient has some disease or not. As an example, we can mention the classification of mammogram images. In such a case, the goal is to detect whether the patient has cancer~\cite{viale2012current, levy2016breast}.
  \item \textbf{Spam Detection:} Another use of classification can be found in detecting spam emails based on the content of the email~\cite{pantel1998spamcop}.
  \item \textbf{Internet Security:} These days, the internet is a crucial part of our lives. With its increasing usage, the number of attacks also increases. An essential part of the defense are intrusion detection systems~\cite{grill2016learning, scarfone2007guide} that search for malicious activities (network attacks) in network traffic. Classification can be used to improve such systems, as shown in~\cite{giacinto2002intrusion, shanbhag2009accurate}.
  \item \textbf{Marketing:} In marketing, the task can be to classify customers based on their buying interests. Such information can be used to build a personalized recommendation system for customers and therefore increase income~\cite{kaefer2005neural, zhang2007building}.
\end{itemize}
From the previous examples, it is clear that classification is a problem present in many sectors. We can also see that many classification problems contained only two classes. For example, we want to detect whether the patient has some disease or not in medical diagnosis. Or in spam detection, we have a class of clear and spam emails. Such problems are usually called binary classification. The rest of the work focuses only on binary classification problems and is organized as follows:
\begin{itemize}
  \item Chapter~\ref{chap: binary classification} introduces the general formulation for binary classification and discussed how to measure the performance of binary classifiers. Furthermore, we show that standard binary classification optimizes overall performance. However, many problems closely tied to binary classification only focus on the performance of the most relevant samples. We introduce three categories of such problems and discuss their relation to binary classification.
  \item Chapter~\ref{chap: framework} introduces a general optimization framework for classification at the top. Many problems fall into this framework even though they are usually considered separate problems. We describe Ranking problems, Accuracy at the Top, and the Neyman-Pearson problem in more detail and show that many formulations from these three categories fall into the framework. Moreover, we derive two new formulations closely related to the existing one. Finally, we discussed the basic properties and relations between introduced formulations. All formulations are introduced in a general form with arbitrary model~$f$, even though many of them have been initially designed only for a linear model. Theoretical properties of the formulations with different models are discussed later.
  \item Chapter~\ref{chap: linear} is dedicated to the linear model and formulations in their primal form, i.e., in the form presented in this chapter. This chapter shows that some formulations have nice properties such as convexity, differentiability, or stability. We derive some theoretical guarantees for the optimal solution based on these properties.
  \item Chapter~\ref{chap: dual} is dedicated to the dual forms of formulations from Table~\ref{tab: summary formulations}. In this chapter, we again assume a linear model only and show that all formulations can be split into two families based on their similarities. Then we derive dual formulations for these two families and show that these formulations are very similar to standard SVM. Using this observation, we use the kernel trick to employ non-linearity into the formulations. Finally, we derive an efficient algorithm for solving the formulations.
  \item In Chapter~\ref{chap: deep}, we assume a nonlinear model. A prototypical example of such a model can be a neural network. The resulting formulations are not decomposable since the decision threshold is always a function of all classification scores. Therefore, it is impossible to use the stochastic descent algorithm directly to solve them. In Chapter~\ref{chap: deep}, we present two approaches for dealing with this problem.
  \item Chapter~\ref{chap: experiments} is dedicated to all numerical experiments.
\end{itemize}
Chapters~\ref{chap: binary classification} and~\ref{chap: framework} are crucial for the whole work since they introduce all formulations that are studied in the rest of the work. On the other hand, Chapters~\ref{chap: linear}, \ref{chap: dual}, and~\ref{chap: deep} study the properties of these formulations in three different settings. Therefore, these three chapters can be read separately. 
